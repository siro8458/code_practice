{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40315142-8445-4a6b-a60e-8ad9fbe55ddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "<io>\n",
    "사업보고서 전체에 대해서 보는 것이 필요하나, 이미 이전의 단어 추출 기반으로 산업을 분류한 것과 유사하게, <br>\n",
    "business description에서 나온 문장 단위에서 token화를 해 준 다음 unigrams와 bigrams를 기반으로 filling date 이후 CAR 을 예측해보고자 한다. <br>\n",
    "대조군으로 Loughran and McDonald 사전 기반으로 긍정, 부정, 긍정부정 비율 등과 비교하여 결과의 정확도를 보고자 한다. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b09ba-4b8b-4c60-96b2-d3b0b68a1e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys, traceback\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "def textmaking(start_num, end_num): #Business description 부분에서 단어 추출하기 위한 함수\n",
    "    try:\n",
    "        df = pd.read_csv('ALL_df.csv', index_col=0)\n",
    "        print(start_num, '~', end_num) #멀티프로세스가 잘 되고 있는지 확인하기 위한 용도\n",
    "\n",
    "        #한번만 설치\n",
    "        #nltk.download('punkt')\n",
    "        #nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "        #word_df = pd.DataFrame()\n",
    "        word_df = pd.DataFrame(columns=['FY', 'CIK', 'NAME', 'word', 'count'])\n",
    "        #ii=0\n",
    "        #if len(word_df) != 0:\n",
    "        #    ii=word_df.loc[len(word_df)-1, 'i']+1\n",
    "\n",
    "        for i in range(start_num, end_num):\n",
    "            err = 1 #단어 추출과는 다르게 문장별로 할껀데, 이전 예외처리들이 하나하나 다시 점검해야되서 귀찮아서 걍 예외처리한것들은 싹다 빼고 할꺼임\n",
    "            intel = 0\n",
    "            morgan = 0\n",
    "            key = 0\n",
    "            ge=0\n",
    "            gen=0\n",
    "            att=0\n",
    "            city=0\n",
    "            edison = 0\n",
    "            cardinal=0\n",
    "            entergy=0\n",
    "            forrester =0\n",
    "            wy=0\n",
    "            MRTX = 0\n",
    "            clean = 0\n",
    "            freddie = 0\n",
    "            fy = df['FY'][i]\n",
    "            cik= df['CIK'][i]\n",
    "            name= df['NAME'][i].replace('/', '-')\n",
    "            name= name.replace('\\\\', '-')\n",
    "            ACCN = df['ACCN'][i]\n",
    "            ACCN1 = df['ACCN'][i].replace('-', '')\n",
    "            url = 'https://www.sec.gov/Archives/edgar/data/'+str(cik)+'/'+str(ACCN1)+'/'+str(ACCN)+'.txt'\n",
    "\n",
    "            headers = {'User-Agent': 'Mozilla'}\n",
    "            res = requests.get(url, headers=headers)\n",
    "            text=[]\n",
    "            if res.status_code == 200:\n",
    "                # BeautifulSoup을 사용하여 HTML 파싱\n",
    "                if i>=256 and i<= 258:\n",
    "                    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    intel = 1\n",
    "                    err = 0\n",
    "                elif (i>=319 and i<=321) or (i>=2010 and i<=2016): #overview 이후 financial 까지 해야되는 경우\n",
    "                    soup = BeautifulSoup(res.text, 'lxml')\n",
    "                    morgan = 1\n",
    "                    err = 0\n",
    "                elif (i>=344 and i<=349) or (i>=1922 and i<=1925): #about 뭐시기로 끊고 바로 legal 까지 대문자 형태로 구분이 되는 경우\n",
    "                    if i<349:\n",
    "                        first = res.text.find(\"ABOUT GENERAL ELECTRIC\")\n",
    "                    elif i<1925:\n",
    "                        first = res.text.find(\"ABOUT MOLINA HEALTHCARE\")\n",
    "                    end = res.text.find(\"LEGAL PROCEEDINGS\")\n",
    "                    tt = res.text[first:end]\n",
    "                    soup = BeautifulSoup(tt, 'lxml')\n",
    "                    ge=1\n",
    "                    err = 0\n",
    "                elif (i>=595 and i<= 601):\n",
    "                    soup = BeautifulSoup(res.text, 'lxml')\n",
    "                    city = 1\n",
    "                    err = 0\n",
    "                    if i == 595:\n",
    "                        city = 2\n",
    "                        err = 0\n",
    "                elif (i>=1710 and i<=1715): #EDISON 형식, CORPORATE STRUCTURE, INDUSTRY AND OTHER INFORMATION 부터 staff 까지\n",
    "                    soup = BeautifulSoup(res.text, 'lxml')\n",
    "                    edison = 1\n",
    "                    err = 0\n",
    "                elif (i>=1753 and i<=1757) or (i>=2031 and i<=2033):#business general 꼴\n",
    "                    soup = BeautifulSoup(res.text, 'lxml')\n",
    "                    cardinal=1\n",
    "                    err = 0\n",
    "                elif (i>=1877 and i<=1883): #OUrbusiness 형식으로 되어있어서 구분이 힘든 애들\n",
    "                    soup = BeautifulSoup(res.text, 'lxml')\n",
    "                    wy = 1\n",
    "                    err = 0\n",
    "                elif (i>=2003 and i<=2009): #entergy 형식들, 아예 형식이 너무 다름\n",
    "                    try: #lxml이 안먹는 애들\n",
    "                        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    except:\n",
    "                        soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "                    entergy = 1\n",
    "                    err = 0\n",
    "                elif (i>=5214 and i<=5220):\n",
    "                    try: #lxml이 안먹는 애들\n",
    "                        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    except:\n",
    "                        soup = BeautifulSoup(res.text, 'lxml')\n",
    "                    MRTX = 1\n",
    "                    err = 0\n",
    "                elif i == 181:\n",
    "                    first = res.text.find(\"BUSINESS SUMMARY\")\n",
    "                    end = res.text.find(\"LEGAL PROCEEDINGS\")\n",
    "                    tt = res.text[first:end]\n",
    "                    soup = BeautifulSoup(tt, 'lxml')\n",
    "                    ge=1\n",
    "                    err = 0\n",
    "                elif i== 7309:\n",
    "                    first = res.text.find(\"THE COMPANY\")\n",
    "                    end = res.text.find(\"LEGAL PROCEEDINGS\")\n",
    "                    tt = res.text[first:end]\n",
    "                    soup = BeautifulSoup(tt, 'lxml')\n",
    "                    ge=1\n",
    "                    err = 0\n",
    "                elif (i>=9933 and i<= 9937): #part i general 로 시작하는 형태\n",
    "                    soup = BeautifulSoup(res.text, 'lxml')\n",
    "                    forrester = 1\n",
    "                    err = 0\n",
    "                elif (i>=10600 and i <= 10604):\n",
    "                    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    freddie = 1\n",
    "                    err = 0\n",
    "                elif (i>=14100 and i<=14101):\n",
    "                    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    clean = 1\n",
    "                    err = 0\n",
    "                elif (i>=14450 and i<=14451):\n",
    "                    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    gen = 1\n",
    "                    err = 0\n",
    "                else:\n",
    "                    try: #lxml이 안먹는 애들\n",
    "                        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                    except:\n",
    "                        soup = BeautifulSoup(res.text, 'lxml')\n",
    "                \n",
    "                if err == 1:\n",
    "                    # 모든 스크립트와 스타일 태그 제거\n",
    "                    for script in soup([\"script\", \"style\"]):\n",
    "                        script.extract()\n",
    "\n",
    "                    # 텍스트 추출\n",
    "                    text = soup.get_text().strip()\n",
    "                    # 텍스트에서 구두점 및 공백 제거 \n",
    "                    text = text.replace('%', 'percent')\n",
    "                    text = re.sub(r'[^\\w\\s\\.]',' ', text)\n",
    "                    text = re.sub(r'\\xa0', ' ', text)    \n",
    "                    text = re.sub(r'\\n', ' ', text)\n",
    "                    text = re.sub(r'\\s+', ' ', text)\n",
    "                    text = text.lower()\n",
    "\n",
    "                    if intel == 1:\n",
    "                        start_index = text.find(\"introduction to our business\")\n",
    "                        first_met = text.find(\"availability of company information\") #처음으로 만나는 끝 직전\n",
    "                        if ((start_index - first_met) < 0) and ((start_index - first_met) > -1000): #목차에서 서로 나타난다는 뜻임 unresolved 항목은 어떻게든 반드시 목차에선 저 문구대로 나올 예정\n",
    "                            #슬라이스 후 item1 business 찾고 unresovlved 그 이후 찾기\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            start_index = text.find(\"introduction to our business\")\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            end_index = text.find(\"availability of company information\") #처음으로 만나는 끝 직전\n",
    "                            text=text[:end_index]\n",
    "                           # print('완료 : ', url, len(text))\n",
    "                            key = 1\n",
    "                        elif ((start_index - first_met) > 0) or ((start_index - first_met) < -1000): #목차에서 item1 business 형태가 아니라는 뜻임 아마 바로 항목으로 갈꺼임 / -1000은 목차가 없는 경우 방지 위해서 즉 바로 item1 나오는거\n",
    "                            #슬라이스 후 바로 unresolved 찾기\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            start_index = text.find(\"introduction to our business\")\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            end_index = text.find(\"availability of company information\") #처음으로 만나는 끝 직전\n",
    "                            text=text[:end_index]\n",
    "                            #print('완료 : ', url, len(text))\n",
    "                            key = 1\n",
    "                    elif i == 2023:\n",
    "                        start_index = text.find(\"business overview\")\n",
    "                        first_met = text.find(\"selected financial data\") #처음으로 만나는 끝 직전\n",
    "                        if ((start_index - first_met) < 0) and ((start_index - first_met) > -1000): #목차에서 서로 나타난다는 뜻임 unresolved 항목은 어떻게든 반드시 목차에선 저 문구대로 나올 예정\n",
    "                            #슬라이스 후 item1 business 찾고 unresovlved 그 이후 찾기\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            start_index = text.find(\"business overview\")\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            end_index = text.find(\"selected financial data\") #처음으로 만나는 끝 직전\n",
    "                            text=text[:end_index]\n",
    "                            #print('완료 : ', url, len(text))\n",
    "                            key = 1\n",
    "                        elif ((start_index - first_met) > 0) or ((start_index - first_met) < -1000): #목차에서 item1 business 형태가 아니라는 뜻임 아마 바로 항목으로 갈꺼임 / -1000은 목차가 없는 경우 방지 위해서 즉 바로 item1 나오는거\n",
    "                            #슬라이스 후 바로 unresolved 찾기\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            start_index = text.find(\"overview\")\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            end_index = text.find(\"selected financial datas\") #처음으로 만나는 끝 직전\n",
    "                            text=text[:end_index]\n",
    "                            #print('완료 : ', url, len(text))\n",
    "                            key = 1\n",
    "                    elif (i >= 15680 and i<= 15685): #갑자기 얘 혼자만 overview 부터 시작함\n",
    "                        start_index = text.find(\"overview\")\n",
    "                        text = text[start_index+len('item'):]\n",
    "                        end_index = text.find(\"unresolved staff comments\")\n",
    "                        text=text[:end_index]\n",
    "                        #print('완료 : ', url, len(text))\n",
    "                        key = 1\n",
    "                    elif gen == 1:\n",
    "                        start_index = text.find('company background')\n",
    "                        text = text[start_index:]\n",
    "                        end_index = text.find('unresolved staff comments')\n",
    "                        text = text[:end_index]\n",
    "                        key = 1\n",
    "                    elif morgan == 1:\n",
    "                        start_index = text.find(\"overview\")\n",
    "                        first_met = text.find(\"selected financial data\") #처음으로 만나는 끝 직전\n",
    "                        if ((start_index - first_met) < 0) and ((start_index - first_met) > -1000): #목차에서 서로 나타난다는 뜻임 unresolved 항목은 어떻게든 반드시 목차에선 저 문구대로 나올 예정\n",
    "                            #슬라이스 후 item1 business 찾고 unresovlved 그 이후 찾기\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            start_index = text.find(\"overview\")\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            end_index = text.find(\"selected financial data\") #처음으로 만나는 끝 직전\n",
    "                            text=text[:end_index]\n",
    "                            #print('완료 : ', url, len(text))\n",
    "                            key = 1\n",
    "                        elif ((start_index - first_met) > 0) or ((start_index - first_met) < -1000): #목차에서 item1 business 형태가 아니라는 뜻임 아마 바로 항목으로 갈꺼임 / -1000은 목차가 없는 경우 방지 위해서 즉 바로 item1 나오는거\n",
    "                            #슬라이스 후 바로 unresolved 찾기\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            start_index = text.find(\"overview\")\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            end_index = text.find(\"selected financial datas\") #처음으로 만나는 끝 직전\n",
    "                            text=text[:end_index]\n",
    "                            #print('완료 : ', url, len(text))\n",
    "                            key = 1\n",
    "                    elif MRTX == 1:\n",
    "                        pattern = r\"business\\s?overview\"\n",
    "                        match = re.search(pattern, text)\n",
    "                        if match:\n",
    "                            start_index=match.end()\n",
    "                            end_index = text[30000:].find(\"unresolved staff comments\") #처음으로 만나는 끝 직전\n",
    "                            if end_index == -1:\n",
    "                                end_index = text[30000:].find(\"unresolved sec staff comments\")\n",
    "                                if end_index== -1:\n",
    "                                    end_index = text[30000:].find(\"legal proceedings\") \n",
    "                            text=text[:end_index+30000]\n",
    "                            #print('완료 : ', url, len(text))\n",
    "                            key = 1\n",
    "                    elif edison == 1:\n",
    "                        start_index = text.find('corporate structure')\n",
    "                        text=text[start_index:]\n",
    "                        end_index = text[30000:].find(\"unresolved staff comments\") #처음으로 만나는 끝 직전\n",
    "                        if end_index == -1:\n",
    "                            end_index = text[30000:].find(\"unresolved sec staff comments\")\n",
    "                            if end_index== -1:\n",
    "                                end_index = text[30000:].find(\"legal proceedings\") \n",
    "                        text=text[:end_index+30000]\n",
    "                        #print('완료 : ', url, len(text))\n",
    "                        key = 1\n",
    "                    elif cardinal == 1:\n",
    "                        pattern = r\"business\\s?general\"\n",
    "                        match = re.search(pattern, text)\n",
    "                        if match:\n",
    "                            start_index = match.end()\n",
    "                            first_met = text.find(\"legal proceedings\") #처음으로 만나는 끝 직전\n",
    "                            if first_met == -1:\n",
    "                                first_met = text.find(\"legal proceedings\")\n",
    "                            if ((start_index - first_met) < 0) and ((start_index - first_met) > -1000): #목차에서 서로 나타난다는 뜻임 unresolved 항목은 어떻게든 반드시 목차에선 저 문구대로 나올 예정\n",
    "                                #슬라이스 후 item1 business 찾고 unresovlved 그 이후 찾기\n",
    "                                text = text[start_index+len('item'):]\n",
    "                                match = re.search(pattern, text)\n",
    "                                if match:\n",
    "                                    start_index = match.end()\n",
    "                                    text = text[start_index+len('item'):]\n",
    "                                    end_index = text[30000:].find(\"legal proceedings\") #처음으로 만나는 끝 직전\n",
    "                                    text=text[:end_index+30000]\n",
    "                                    #print('완료 : ', url, len(text))\n",
    "                                    key = 1\n",
    "                            elif ((start_index - first_met) > 0) or ((start_index - first_met) < -1000): #목차에서 item1 business 형태가 아니라는 뜻임 아마 바로 항목으로 갈꺼임 / -1000은 목차가 없는 경우 방지 위해서 즉 바로 item1 나오는거\n",
    "                                #슬라이스 후 바로 unresolved 찾기\n",
    "                                text = text[start_index+len('item'):]\n",
    "                                end_index = text[30000:].find(\"legal proceedings\") #처음으로 만나는 끝 직전\n",
    "                                text=text[:end_index+30000]\n",
    "                                #print('완료 : ', url, len(text))\n",
    "                                key = 1\n",
    "                    elif ge == 1:\n",
    "                        key = 1\n",
    "                        #print('완료 : ', url, len(text))\n",
    "                    elif forrester == 1:\n",
    "                        pattern = r\"part\\s?i\\s?general\"\n",
    "                        match = re.search(pattern, text)\n",
    "                        if match:\n",
    "                            start_index=match.end()\n",
    "                            text = text[start_index+len('item'):]\n",
    "                            end_index = text[30000:].find(\"unresolved staff comments\") #처음으로 만나는 끝 직전\n",
    "                            if end_index == -1:\n",
    "                                end_index = text[30000:].find(\"unresolved sec staff comments\")\n",
    "                                if end_index== -1:\n",
    "                                    end_index = text[30000:].find(\"legal proceedings\") \n",
    "                            text=text[:end_index+30000]\n",
    "                            #print('완료 : ', url, len(text))\n",
    "                            key = 1\n",
    "                    elif wy == 1:\n",
    "                        start_index = text.find('our businesswe are')\n",
    "                        text=text[start_index:]\n",
    "                        end_index = text[30000:].find(\"unresolved staff comments\") #처음으로 만나는 끝 직전\n",
    "                        if end_index == -1:\n",
    "                            end_index = text[30000:].find(\"unresolved sec staff comments\")\n",
    "                            if end_index== -1:\n",
    "                                end_index = text[30000:].find(\"legal proceedings\") \n",
    "                        text=text[:end_index+30000]\n",
    "                        #print('완료 : ', url, len(text))\n",
    "                        key = 1\n",
    "                    elif city > 0:\n",
    "                        start_index = text.find('citigroups history')\n",
    "                        text=text[start_index:]\n",
    "                        if city == 2:\n",
    "                            end_index = text.find('risk managementoverview')\n",
    "                        elif city == 1:\n",
    "                            end_index = text.find('managing global risk table of contents')\n",
    "                        text=text[:end_index]\n",
    "                        key = 1\n",
    "                        #print('완료 : ', url, len(text)) \n",
    "                    elif freddie == 1:\n",
    "                        start_index = text.find('freddie mac is a gse')\n",
    "                        text=text[start_index:]\n",
    "                        end_index = text.find('we are involved as a party')\n",
    "                        text=text[:end_index]\n",
    "                        key = 1\n",
    "                        #print('완료 : ', url, len(text)) \n",
    "                    elif entergy == 1:\n",
    "                        text = re.sub(r'font|style', ' ', text)\n",
    "                        start_index = text.find('entergy is an integrated energy company')\n",
    "                        text = text[start_index:]\n",
    "                        end_index = text.find('entergy arkansas inc and subsidiaries')\n",
    "                        text = text[:end_index]\n",
    "                        #print('완료 : ', url, len(text))\n",
    "                        key = 1\n",
    "                    elif clean == 1:\n",
    "                        start_index = text.find('general business overview')\n",
    "                        text = text[start_index:]\n",
    "                        end_index = text.find('unresolved staff comments')\n",
    "                        text = text[:end_index]\n",
    "                        #print('완료 : ', url, len(text))\n",
    "                        key = 1\n",
    "                    else:\n",
    "                        pattern = r\".*?i{0,2}tems?\\s?(no.\\s?)?(1|i|(1 i))?\\s?(1a\\s)?(2|1a|and\\s2\\s?)?(.\\s?)?(discussion of|description of|our)?\\s?(the\\s?)?busines\"\n",
    "                        match = re.search(pattern, text)\n",
    "                        if match:\n",
    "                            start_index = match.end()\n",
    "                            first_met = text.find(\"unresolved staff comments\") #처음으로 만나는 끝 직전\n",
    "                            if first_met == -1:\n",
    "                                first_met = text.find(\"unresolved sec staff comments\")\n",
    "                                if first_met== -1:\n",
    "                                    first_met = text.find(\"item 2 properties\") \n",
    "                                    if first_met == -1:\n",
    "                                        first_met = text.find(\"legal proceedings\") \n",
    "                            if ((start_index - first_met) < 0) and ((start_index - first_met) > -1000): #목차에서 서로 나타난다는 뜻임 unresolved 항목은 어떻게든 반드시 목차에선 저 문구대로 나올 예정\n",
    "                                #슬라이스 후 item1 business 찾고 unresovlved 그 이후 찾기\n",
    "                                text = text[start_index+len('item'):]\n",
    "                                match = re.search(pattern, text)\n",
    "                                if match:\n",
    "                                    start_index = match.end()\n",
    "                                    text = text[start_index+len('item'):]\n",
    "                                    end_index = text[10000:].find(\"unresolved staff comments\") #처음으로 만나는 끝 직전\n",
    "                                    if end_index == -1:\n",
    "                                        end_index = text[10000:].find(\"unresolved sec staff comments\")\n",
    "                                        if end_index== -1:\n",
    "                                            end_index = text[10000:].find(\"item 2 properties\") \n",
    "                                            if end_index == -1:\n",
    "                                                end_index = text[10000:].find(\"legal proceedings\") \n",
    "                                    text=text[:end_index+10000]\n",
    "                                    #print('완료 : ', url, len(text))\n",
    "                                    key = 1\n",
    "                            elif ((start_index - first_met) > 0) or ((start_index - first_met) < -1000): #목차에서 item1 business 형태가 아니라는 뜻임 아마 바로 항목으로 갈꺼임 / -1000은 목차가 없는 경우 방지 위해서 즉 바로 item1 나오는거\n",
    "                                #슬라이스 후 바로 unresolved 찾기\n",
    "                                text = text[start_index+len('item'):]\n",
    "                                end_index = text[10000:].find(\"unresolved staff comments\") #처음으로 만나는 끝 직전\n",
    "                                if end_index == -1:\n",
    "                                    end_index = text[10000:].find(\"unresolved sec staff comments\")\n",
    "                                    if end_index== -1:\n",
    "                                        end_index = text[10000:].find(\"item 2 properties\") \n",
    "                                        if end_index == -1:\n",
    "                                            end_index = text[10000:].find(\"legal proceedings\") \n",
    "                                text=text[:end_index+10000]\n",
    "                                #print('완료 : ', url, len(text))\n",
    "                                key = 1\n",
    "                        else:\n",
    "                            print('error2 : ', url)\n",
    "\n",
    "                    #설치는 이미 했으면 필요는 없음\n",
    "                    #nltk.download('punkt')\n",
    "                    #nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "                    if(key == 1):\n",
    "                        text = text.replace('u.s.', 'us').replace('e.g.', 'eg')\n",
    "                        sentences = text.lower().split('.')\n",
    "\n",
    "                        #혹시 모르니 정제한 txt 파일을 저장을 해 놓자\n",
    "                        #text_str = ''.join(text)\n",
    "                        with open(\"C:/Users/이세준/자산평가/sentence/\"+str(name)+\"-\"+str(fy)+\".txt\", 'w', encoding='utf-8') as file:\n",
    "                            for sentence in sentences:\n",
    "                                file.write(sentence.strip() + '\\n') \n",
    "                            file.close()\n",
    "                    else:\n",
    "                        print('error3', url)\n",
    "\n",
    "            else: \n",
    "                print('통신에러')\n",
    "    except:\n",
    "        logging.error(traceback.format_exc())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6aad95-6d8c-4e56-8caf-24fdc8e606d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, TimeoutError\n",
    "import pandas as pd\n",
    "\n",
    "def get_physical_cores():\n",
    "    if os.name == 'posix':  # For Linux and macOS\n",
    "        return int(os.environ.get('OMP_NUM_THREADS', multiprocessing.cpu_count() // 2))\n",
    "    elif os.name == 'nt':  # For Windows\n",
    "        return int(os.environ.get('NUMBER_OF_PROCESSORS', multiprocessing.cpu_count() // 2))\n",
    "    else:\n",
    "        return multiprocessing.cpu_count() // 2\n",
    "\n",
    "physical_cores = get_physical_cores()\n",
    "\n",
    "# 적절한 스레드 개수를 선택하세요 (예: CPU 코어 수)\n",
    "num_threads = physical_cores//2\n",
    "print(\"Using threads:\", num_threads)\n",
    "\n",
    "#ranges = [(i, i + 100) for i in range(11800, 15000, 100)] + [(15000, 15966)]\n",
    "ranges = [(i, i + 100) for i in range(0, 15000, 1000)] + [(15000, 15966)]\n",
    "\n",
    "result_data = pd.DataFrame()\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    executor.map(lambda x: textmaking(*x), ranges)\n",
    "    #results = executor.map(lambda x: textmaking(*x), ranges)\n",
    "    #for group_data_s in results:\n",
    "        #result_data = pd.concat([result_data, group_data_s])\n",
    "        \n",
    "#result_data.to_csv('resutl.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319798d5-b22f-482c-a8b1-2cd7be3cc610",
   "metadata": {},
   "source": [
    "### 텍스트 데이터에서 grams 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f36dd-41ea-40ce-a8bd-fc492c231211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.path.dirname(os.path.realpath(__file__))\n",
    "dir = \"C:/Users/이세준/자산평가/sentence/\"\n",
    "files = os.listdir(dir)\n",
    "i = 0\n",
    "\n",
    "with open(dir+files[i], 'r', encoding='utf-8') as file:\n",
    "    file_content = file.read()\n",
    "firmname = files[i].split('-')[0]\n",
    "year = files[i].split('-')[1]\n",
    "\n",
    "file_content = file_content.split('\\n') #\\n 형태로 메모장에 기록되어 있으므로 나누어줌\n",
    "tokenList = [sent.split() for sent in file_content]\n",
    "tokenList[:5] #문장을 \\n으로 나누어서 생성, 앞 5개만 예시로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c05a7-1af5-40b7-885e-f258edbb5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import os\n",
    "\n",
    "\n",
    "#처음 한번만 실행\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#stop word\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Porter Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "processed_stemmed_list = []\n",
    "for sentence in tokenList:\n",
    "    processed_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in stop_words or re.match(r'\\d+', word): #stop_word나 숫자를 _로 변경\n",
    "            word = '_'\n",
    "        # Porter Stemmer 적용\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        processed_sentence.append(stemmed_word)\n",
    "    processed_stemmed_list.append(processed_sentence)\n",
    "\n",
    "print('기존 각 문장의 형태')\n",
    "print(tokenList[:5])\n",
    "print('머신러닝 위한 처리 후 문장의 형태')\n",
    "print(processed_stemmed_list[:5])\n",
    "\n",
    "from nltk.util import bigrams, trigrams\n",
    "\n",
    "unigrams = [word for sentence in processed_stemmed_list for word in sentence if word != '_']\n",
    "\n",
    "# Bigrams 생성 (_는 제거, 포함 안함)\n",
    "bigrams_list = [bg for sentence in processed_stemmed_list for bg in bigrams(sentence) if '_' not in bg]\n",
    "\n",
    "# Trigrams 생성 (_는 제거, 포함 안함) -> 트라이그램은 거의 없는거 같으니 제외한다.\n",
    "#trigrams_list = [tg for sentence in processed_stemmed_list[:5] for tg in trigrams(sentence) if '_' not in tg]\n",
    "\n",
    "print('unigrams 앞 5개 예시')\n",
    "print(unigrams[:5])\n",
    "\n",
    "print('biigrams 앞 5개 예시')\n",
    "print(bigrams_list[:5])\n",
    "\n",
    "from collections import Counter\n",
    "uni_count = Counter(unigrams)\n",
    "bi_count = Counter(bigrams_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd459c83-d61a-4eff-affa-974003ec58da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 예시로 10개만 추출하여서 빈도수 낮은거 없애는 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f1c068-b73f-492b-a5ab-f3d09148439a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir = \"C:/Users/이세준/자산평가/sentence/\"\n",
    "files = os.listdir(dir)\n",
    "\n",
    "firm_year_gram_count = {}\n",
    "for i in range(0, 10):#len(files)):\n",
    "    with open(dir+files[i], 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "    firmname = files[i].split('-')[0]\n",
    "    year = files[i].split('-')[1]\n",
    "\n",
    "    file_content = file_content.split('\\n') #\\n 형태로 메모장에 기록되어 있으므로 나누어줌\n",
    "    tokenList = [sent.split() for sent in file_content]\n",
    "\n",
    "    #stop word\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Porter Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    processed_stemmed_list = []\n",
    "    for sentence in tokenList:\n",
    "        processed_sentence = []\n",
    "        for word in sentence:\n",
    "            if word in stop_words or re.match(r'\\d+', word): #stop_word나 숫자를 _로 변경\n",
    "                word = '_'\n",
    "            # Porter Stemmer 적용\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            processed_sentence.append(stemmed_word)\n",
    "        processed_stemmed_list.append(processed_sentence)\n",
    "\n",
    "    unigrams = [word for sentence in processed_stemmed_list for word in sentence if word != '_']\n",
    "    uni_count = Counter(unigrams)\n",
    "\n",
    "    bigrams_list = [bg for sentence in processed_stemmed_list for bg in bigrams(sentence) if '_' not in bg]\n",
    "    bi_count = Counter(bigrams_list)\n",
    "    \n",
    "    key = f\"{firmname}-{year}\"\n",
    "    firm_year_gram_count[key] = {'unigrams': uni_count, 'bigrams': bi_count}\n",
    "    \n",
    "#dictionary 형태로 firm_name과 year로 결합됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a0303-9167-45a7-bb7f-40c861f267ba",
   "metadata": {},
   "source": [
    "### 10세트만 추출했으므로 3세트에 포함 안되는거 제거하는 방식 취해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65197d1b-e039-45a2-8441-96dd5a1f9a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 각 n-gram이 등장하는 세트 수를 세기 위한 dictionary\n",
    "ngram_appearance_sets = defaultdict(set)\n",
    "\n",
    "# 각 n-gram이 등장하는 세트 수를 셈\n",
    "for key in firm_year_gram_count:\n",
    "    for ngram in firm_year_gram_count[key]['unigrams']:\n",
    "        ngram_appearance_sets[ngram].add(key)\n",
    "    for ngram in firm_year_gram_count[key]['bigrams']:\n",
    "        ngram_appearance_sets[ngram].add(key)\n",
    "\n",
    "print('예시로 flower 가 나오는 세트수')\n",
    "print(ngram_appearance_sets['flower'])\n",
    "        \n",
    "# 3개 세트 이상 ngram 들만 key값을 추춮\n",
    "filtered_ngrams = {ngram for ngram, sets in ngram_appearance_sets.items() if len(sets) >= 3}\n",
    "\n",
    "# firm_year_gram_count 내에서 추출된거만 따로 빼넴\n",
    "for key in firm_year_gram_count:\n",
    "    firm_year_gram_count[key]['unigrams'] = Counter({ngram: count for ngram, count in firm_year_gram_count[key]['unigrams'].items() if ngram in filtered_ngrams})\n",
    "    firm_year_gram_count[key]['bigrams'] = Counter({ngram: count for ngram, count in firm_year_gram_count[key]['bigrams'].items() if ngram in filtered_ngrams})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaeae80-bdd3-47f4-8a34-00d0ec802653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infrequent_ngrams = {ngram: sets for ngram, sets in ngram_appearance_sets.items() if len(sets) <= 3}\n",
    "\n",
    "# 결과 출력\n",
    "print('추가 예시로 3세트 밑에서 나오는 unigram 하나만 보면 ')\n",
    "first_key = list(infrequent_ngrams.keys())[0]\n",
    "print('단어 : ', first_key)\n",
    "print(ngram_appearance_sets[first_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8784739-93b3-4628-9bb1-939b503b8c87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 전체 수집한 txt 파일을 바탕으로 전체 세트에서 10개 미만으로 나타나는 gram들은 제외한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b98d2-d4f0-405f-a6f3-09fa70f12c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dir = \"C:/Users/이세준/자산평가/sentence/\"\n",
    "files = os.listdir(dir)\n",
    "\n",
    "firm_year_gram_count = {}\n",
    "sample = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(files)):\n",
    "    with open(dir+files[i], 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "    file_name = files[i]\n",
    "    # 연도 추출 - 문자 사이의 4자리 숫자임\n",
    "    year_match = re.search(r'\\b\\d{4}\\b', file_name)\n",
    "    year = year_match.group() if year_match else None\n",
    "    # 회사 이름 추출 (연도 바로 앞의 - 이전이 전부 회사이름임)\n",
    "    if year:\n",
    "        firmname = file_name.split(year)[0].rstrip('-')\n",
    "    else:\n",
    "        firmname = None\n",
    "    sample.loc[i, 'name'] = firmname\n",
    "    sample.loc[i, 'year'] = year\n",
    "\n",
    "    file_content = file_content.split('\\n') #\\n 형태로 메모장에 기록되어 있으므로 나누어줌\n",
    "    tokenList = [sent.split() for sent in file_content]\n",
    "\n",
    "    #stop word\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Porter Stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    processed_stemmed_list = []\n",
    "    for sentence in tokenList:\n",
    "        processed_sentence = []\n",
    "        for word in sentence:\n",
    "            if word in stop_words or re.match(r'\\d+', word): #stop_word나 숫자를 _로 변경\n",
    "                word = '_'\n",
    "            # Porter Stemmer 적용\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            processed_sentence.append(stemmed_word)\n",
    "        processed_stemmed_list.append(processed_sentence)\n",
    "\n",
    "    unigrams = [word for sentence in processed_stemmed_list for word in sentence if word != '_']\n",
    "    uni_count = Counter(unigrams)\n",
    "\n",
    "    bigrams_list = [bg for sentence in processed_stemmed_list for bg in bigrams(sentence) if '_' not in bg]\n",
    "    bi_count = Counter(bigrams_list)\n",
    "    \n",
    "    key = f\"{firmname}-{year}\"\n",
    "    firm_year_gram_count[key] = {'unigrams': uni_count, 'bigrams': bi_count}\n",
    "    \n",
    "#dictionary 형태로 firm_name과 year로 결합됨\n",
    "\n",
    "ngram_appearance_sets = defaultdict(set)\n",
    "\n",
    "# 각 n-gram이 등장하는 세트 수를 셈\n",
    "for key in firm_year_gram_count:\n",
    "    for ngram in firm_year_gram_count[key]['unigrams']:\n",
    "        ngram_appearance_sets[ngram].add(key)\n",
    "    for ngram in firm_year_gram_count[key]['bigrams']:\n",
    "        ngram_appearance_sets[ngram].add(key)\n",
    "        \n",
    "# 10개 세트 이상 ngram 들만 key값을 추춮\n",
    "filtered_ngrams = {ngram for ngram, sets in ngram_appearance_sets.items() if len(sets) >= 10}\n",
    "\n",
    "# firm_year_gram_count 내에서 추출된거만 따로 빼넴\n",
    "for key in firm_year_gram_count:\n",
    "    firm_year_gram_count[key]['unigrams'] = Counter({ngram: count for ngram, count in firm_year_gram_count[key]['unigrams'].items() if ngram in filtered_ngrams})\n",
    "    firm_year_gram_count[key]['bigrams'] = Counter({ngram: count for ngram, count in firm_year_gram_count[key]['bigrams'].items() if ngram in filtered_ngrams})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252aef2b-35ce-44e8-bc2a-f62fc49e815e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#애써 만든 dictionary 시간관계상 나중에 써야되면 불러오려고\n",
    "import pickle\n",
    "\n",
    "sample.to_csv('gram_sample.csv', index=False, encoding='cp949')\n",
    "\n",
    "# firm_year_gram_count를 파일로 저장\n",
    "with open('firm_year_gram_count.pkl', 'wb') as f:\n",
    "    pickle.dump(firm_year_gram_count, f)\n",
    "    \n",
    "with open('firm_year_gram_count.pkl', 'rb') as f:\n",
    "    firm_year_gram_count = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d833ef-0a7a-4d6b-9ae8-67ce5b935538",
   "metadata": {},
   "source": [
    "### CAR 등 위해서 wrds 에서 결합하고자 cik 합침"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55f177-83e5-4da9-8407-88ee38fe0c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv('gram_sample.csv', encoding='cp949')\n",
    "alldf = pd.read_csv('ALL_df.csv', encoding='cp949')\n",
    "alldf = alldf[['CIK', 'NAME']]\n",
    "sample = sample.merge(alldf, left_on='name', right_on='NAME', how='left')\n",
    "sample = sample.drop(columns='NAME')\n",
    "sample = sample.drop_duplicates(subset=['name', 'year', 'CIK'])\n",
    "sample.to_csv('gram_sample_CIK.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f6860-682d-4cb6-b98a-f9551fe85efc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 없는거 몇개는 수기로 변경하고, 이후 wrds로 부터 주가, sec api를 이용하여 가진 10-K의 공시일을 받아옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7988a64-1110-4555-8457-a95b61ed6498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = pd.read_csv('gram_sample_CIK.csv', encoding='cp949')\n",
    "\n",
    "import requests\n",
    "\n",
    "for i in range(0, len(ss)):\n",
    "    cik = ss['CIK'][i]\n",
    "    year = ss['year'][i]\n",
    "    CIK = str(cik).zfill(10)\n",
    "    url = 'https://data.sec.gov/api/xbrl/companyfacts/CIK'+CIK+'.json' #cik를 획득 하여 https://www.sec.gov/Archives/edgar/data/0000320193/0001193125-09-214859.txt 와 같이 cik-10k 형식 추출 예정\n",
    "    headers = {'User-Agent': 'Mozilla'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "\n",
    "    if res.status_code == 200:\n",
    "        data = res.json()\n",
    "\n",
    "        # facts 항목 가져오기\n",
    "        facts = data.get('facts', {})\n",
    "        if len(facts) >0:\n",
    "            key1 = list(facts.keys())[0]\n",
    "            key2 = list(facts[key1].keys())[0]\n",
    "            key3 = list(facts[key1][key2]['units'].keys())[0]\n",
    "            it =facts[key1][key2]['units'][key3]\n",
    "            selected_items = []\n",
    "            for item in it:\n",
    "                if item.get('form') == '10-K' and item.get('fy') == year :\n",
    "                    filed = item.get('filed', '')\n",
    "                    ss.loc[i,'filed'] = filed #공시날짜를 받기 위해서\n",
    "ss.to_csv('gram_sample_CIK_filed.csv', index=False, encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86484631-b107-496d-b3d8-ebea7d074a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss.head() #filed 가 공시 날짜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32264768-94ed-434d-b70f-91500c0d53ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pr = pd.read_csv('gram_retrun.csv', encoding='cp949', low_memory=False)\n",
    "pr = pr.drop(columns=['gvkey', 'iid'])\n",
    "pr['diff'] = pr.groupby('cik', group_keys=False)['prccd'].apply(lambda x: np.log(x / x.shift(1))) #cik별 로그수익률 계산\n",
    "#CAR을 위해서 AR을 capm 등이 아닌(각 회사별로 market index가 너무 제각각이라) 이전 250일 평균으로 간단하게 해봄\n",
    "pr['rolling_avg'] = pr.groupby('cik')['diff'].transform(lambda x: x.rolling(window=250, min_periods=250).mean()) #이전 250일 평균\n",
    "pr['AR'] = pr['diff'] - pr['rolling_avg'] #AR = r - E(r)\n",
    "pr = pr.drop(columns=['rolling_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb560bd-c7ec-45f9-8c03-c8af4a09add2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = pd.read_csv('gram_sample_CIK_filed.csv', encoding='cp949')\n",
    "for i in range(0, len(ss)):\n",
    "    key = ss.loc[i, 'name']+'-'+str(ss.loc[i, 'year']) #우리가 사용할 회사명-year 형태의 key 값\n",
    "    cik = ss.loc[i, 'CIK']\n",
    "    filed = ss.loc[i, 'filed']\n",
    "    filtered_rows = pr[(pr['cik'] == cik) & (pr['datadate'] >= filed)].copy() #cik가 만족하고, filed 즉 공시 이후 날짜를 기준으로 \n",
    "    filtered_rows['datadate'] = pd.to_datetime(filtered_rows['datadate'])#nsmallest 를 쓰기 위해서 pd.datetime으로 바꾸고\n",
    "    selected_rows = filtered_rows.nsmallest(2, 'datadate') #가장 날짜 빠른 두 날짜를 기준으로\n",
    "    ar_sum = selected_rows['AR'].sum() #AR의 합을 구하고\n",
    "    firm_year_gram_count[key]['CAR[0,1]'] = ar_sum #그걸 dictionary에 넣어놓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016353e-2c25-4370-a9e8-13fa0fd2669c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CAR 구한거 까지 pickle로 합쳐줌 -> 혹시 이후에 다시 할 수도 있으니...\n",
    "# firm_year_gram_count를 파일로 저장\n",
    "with open('firm_year_gram_count_car.pkl', 'wb') as f:\n",
    "    pickle.dump(firm_year_gram_count, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e367b8fa-e84d-46c3-a786-eabaf6e98e2e",
   "metadata": {},
   "source": [
    "<io>\n",
    "    SVM 부터는 여기서부터, 후에 회귀 분석시 머신러닝 뿐만 아니라 대조군 느낌으로 LM 긍정 부정 단어집도 사용할 예정임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b1774-bd7d-400e-9c22-5e85cdb5fc74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "#다시 pickle 불러옴\n",
    "with open('firm_year_gram_count_car.pkl', 'rb') as f:\n",
    "    firm_year_gram_count = pickle.load(f)\n",
    "    \n",
    "ss = pd.read_csv('gram_sample_CIK_filed.csv', encoding='cp949')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645233b0-adba-4000-90d3-387134e77ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loughran-McDonald Master Dictionary 기반, 긍정, 부정 단어  추출\n",
    "LM = pd.read_csv('Loughran-McDonald_MasterDictionary_1993-2021.csv', encoding='cp949')\n",
    "LM['Word'] = LM['Word'].str.lower()\n",
    "LM = LM[['Word', 'Negative', 'Positive']]\n",
    "LM['Negative'] = (LM['Negative'] != 0).astype(int)\n",
    "LM['Positive'] = (LM['Positive'] != 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99aac4-bb98-4f33-b4cc-dcc53e327954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "LM['Stemmed_Word'] = LM['Word'].apply(lambda x: stemmer.stem(str(x)) if pd.notnull(x) else x)\n",
    "LM = LM[['Stemmed_Word', 'Negative', 'Positive']]\n",
    "LM = LM.drop_duplicates()\n",
    "LM.to_csv('LM.csv', index=False) #LM단어들 어근 (stem 기준으로 긍정, 부정 나누어봄)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9f35d-9d5a-460a-a1be-339699c11e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(ss)):\n",
    "    ss.loc[i,'key'] = ss.loc[i, 'name']+'-'+str(ss.loc[i, 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a2d7c-7571-4711-abed-db3e44e144df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.head() #key 값도 같이 넣어서 이후에 다루기 편하도록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375be19-b5fe-43f8-89dc-b30b25626f26",
   "metadata": {},
   "source": [
    "### dictionary에 LM 긍정, 부정 단어 비율 추가해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b82de3-9b25-4295-8043-2e5f94d3d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# 긍정, 부정 단어를 위에서 정제한 LM데이터프레임에서 리스트로 추출함\n",
    "positive_words = LM[LM['Positive'] == 1]['Stemmed_Word'].tolist()\n",
    "negative_words = LM[LM['Negative'] == 1]['Stemmed_Word'].tolist()\n",
    "\n",
    "# pickle 파일에서 데이터 로드 (여기서부터 할 수도 있어서 위에서 불러왔지만 다시 불러옴)\n",
    "with open('firm_year_gram_count_car.pkl', 'rb') as f:\n",
    "    firm_year_gram_count = pickle.load(f)\n",
    "con = pd.read_csv('gram_control.csv')\n",
    "# 각 key에 대해 긍정 및 부정 단어 비율 계산\n",
    "for key in firm_year_gram_count:\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    # unigram 즉 공시 보고서에서 얼마나 긍정,부정단어 비율을 차지하는지를 고려해ㅗㅁ\n",
    "    for word in firm_year_gram_count[key]['unigrams']:\n",
    "        if word in positive_words:\n",
    "            pos_count += 1\n",
    "        elif word in negative_words:\n",
    "            neg_count += 1\n",
    "        total_count += 1\n",
    "\n",
    "    if total_count > 0:\n",
    "        firm_year_gram_count[key]['positive_ratio'] = pos_count / total_count\n",
    "        firm_year_gram_count[key]['negative_ratio'] = neg_count / total_count\n",
    "        firm_year_gram_count[key]['PN'] = (pos_count - neg_count) / (pos_count + neg_count) #2011 price 방식\n",
    "        firm_year_gram_count[key]['PN2'] = (pos_count - neg_count) / total_count #전체 대비\n",
    "    else:\n",
    "        firm_year_gram_count[key]['positive_ratio'] = 0\n",
    "        firm_year_gram_count[key]['negative_ratio'] = 0\n",
    "        firm_year_gram_count[key]['PN'] = 0\n",
    "        firm_year_gram_count[key]['PN2'] = 0\n",
    "\n",
    "    #통제변수도 같이 넣어줌\n",
    "    def get_value(df, cik, year, column): #값이 없는 경우 대비\n",
    "        filtered_df = df[(df['cik'] == cik) & (df['fyear'] == year)]\n",
    "        if not filtered_df.empty:\n",
    "            return filtered_df[column].iloc[0]\n",
    "        return None\n",
    "    \n",
    "    cik = ss[ss['key']==key]['CIK'].iloc[0]\n",
    "    year = ss[ss['key']==key]['year'].iloc[0]\n",
    "    bperhare = get_value(con, cik, year, 'bpershare')\n",
    "    sale = get_value(con, cik, year, 'sale')\n",
    "    lnmkv = get_value(con, cik, year, 'ln(mkv)')\n",
    "    firm_year_gram_count[key]['sale'] = sale\n",
    "    firm_year_gram_count[key]['lnmkv'] = lnmkv\n",
    "    firm_year_gram_count[key]['bperhare'] = bperhare\n",
    "\n",
    "\n",
    "\n",
    "#긍정, 부정 비율까지도 합쳐줌.. 혹시 다시 쓸수도 있으니\n",
    "with open('firm_year_gram_count_car_LMratio.pkl', 'wb') as f:\n",
    "    pickle.dump(firm_year_gram_count, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "901f87c0-0999-42ae-ad43-cdb62c5b5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "#다시 pickle 불러옴\n",
    "with open('firm_year_gram_count_car_LMratio.pkl', 'rb') as f:\n",
    "    firm_year_gram_count = pickle.load(f)\n",
    "    \n",
    "ss = pd.read_csv('gram_sample_CIK_filed.csv', encoding='cp949')\n",
    "for i in range(0, len(ss)):\n",
    "    ss.loc[i,'key'] = ss.loc[i, 'name']+'-'+str(ss.loc[i, 'year'])\n",
    "\n",
    "import cupy as cp\n",
    "# 전체 unigrams와 bigrams 집합 생성\n",
    "all_unigrams = set()\n",
    "all_bigrams = set()\n",
    "for firm in firm_year_gram_count:\n",
    "    all_unigrams.update(firm_year_gram_count[firm]['unigrams'].keys())\n",
    "    all_bigrams.update(firm_year_gram_count[firm]['bigrams'].keys())\n",
    "\n",
    "# 전체 어휘 집합 생성\n",
    "vocabulary = list(all_unigrams) + ['_'.join(bigram) for bigram in all_bigrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a956bfbe-49a6-4e2d-80a0-28053c0b876f",
   "metadata": {},
   "source": [
    "# 판다스(cpu)사용 vocal 이용 단어 count된 데이터프레임만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2811a98-86f1-4994-be32-c0141fec91ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#ii=len(df)\n",
    "batch_size = 1000\n",
    "\n",
    "total_firms = le(ss)\n",
    "# 열 이름을 숫자 형태로 지정\n",
    "column_names = list(range(len(vocabulary)))\n",
    "\n",
    "\n",
    "for k in range(0, total_firms, batch_size):\n",
    "    # 데이터프레임 초기화\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    # 각 key에 대한 데이터 처리\n",
    "    for i in range(k, min(k + batch_size, total_firms)):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        # 각 단어의 빈도를 저장할 리스트\n",
    "        firm_vector = [0] * len(vocabulary)\n",
    "        for j, word in enumerate(vocabulary):\n",
    "            if word in firm_year_gram_count[firm]['unigrams']:\n",
    "                firm_vector[j] = firm_year_gram_count[firm]['unigrams'][word]\n",
    "            elif word in firm_year_gram_count[firm]['bigrams']:\n",
    "                firm_vector[j] = firm_year_gram_count[firm]['bigrams'][word]\n",
    "    \n",
    "        # 데이터프레임에 행 추가\n",
    "        df2 = pd.DataFrame([firm_vector], columns=column_names)\n",
    "        df = pd.concat([df, df2], ignore_index=True)\n",
    "    df.to_pickle(str(i)+\".pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f90e41-8f95-4b80-9d82-135641949901",
   "metadata": {},
   "source": [
    "### 14105개에 대해서 최대 500개 까지가 현재 사양에서 돌아가는 한계라서 455개씩 배치형태를 이용하여 SVR해보기로함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad69555-4557-4066-96a3-2a182eec43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import cuml\n",
    "import cudf\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "ss = pd.read_csv('gram_sample_CIK_filed.csv', encoding='cp949')\n",
    "for i in range(0, len(ss)):\n",
    "    ss.loc[i,'key'] = ss.loc[i, 'name']+'-'+str(ss.loc[i, 'year'])\n",
    "\n",
    "with open('firm_year_gram_count_car_LMratio.pkl', 'rb') as f:\n",
    "    firm_year_gram_count = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6b73dd-be79-4ab6-b2e1-2eb6fc6c7b80",
   "metadata": {},
   "source": [
    "### SVR기반 CAR 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb767d3-648b-4e7c-a92f-cd8341ad1536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 SVR 학습 시간 (GPU): 2208.715969324112\n",
      "전체 RMSE: 0.1146646217346256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#svr_model 구축\n",
    "svr_model = cuml.SVR(kernel='rbf')\n",
    "\n",
    "batch = 455\n",
    "end = len(ss)\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    batch_end = min(batch_start + batch, end)\n",
    "    pk = pd.read_pickle(str(batch_end)+\"_1.pkl\") \n",
    "    pk = pk.astype('float32')\n",
    "    pk_cudf = cudf.DataFrame.from_pandas(pk)\n",
    "    \n",
    "    \n",
    "    y = []\n",
    "    for i in range(batch_start, batch_end):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "    y_cudf = cudf.Series(y['CAR'])    \n",
    "\n",
    "    #머신러닝 자체의 시간을 계산해봄\n",
    "    start_time = time.time() \n",
    "    svr_model.fit(pk_cudf, y_cudf)\n",
    "    predictions = svr_model.predict(pk_cudf)\n",
    "    predictions_np = predictions.to_numpy()\n",
    "    mse = mean_squared_error(y['CAR'], predictions_np) #mse 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    svr=pd.DataFrame(predictions_np, columns=['SVR'])\n",
    "    svr = pd.concat([y, svr], axis=1)\n",
    "    svr.to_csv(str(batch_end)+'_SVR_GPU.csv', encoding='cp949') #svr.to_csv(str(batch_start)+'_'+str(batch_end)+'.csv', encoding='cp949') \n",
    "    end_time = time.time()\n",
    "    # 총 걸린시간에 합산함\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    del pk, pk_cudf, y, y_cudf ,svr, predictions, predictions_np\n",
    "    gc.collect()  \n",
    "\n",
    "print('총 SVR 학습 시간 (GPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del svr_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c4344-a87e-4ba1-87a3-b3149084111a",
   "metadata": {},
   "source": [
    "### CPU SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a24435f-abbe-4732-b314-f2f20c45dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 SVR 학습 시간 (CPU): 546.223879814148\n",
      "전체 RMSE: 0.11466489642813031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# CPU 기반 SVR 모델 구축\n",
    "svr_model = SVR(kernel='rbf')\n",
    "\n",
    "batch = 455\n",
    "end = len(ss)\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    batch_end = min(batch_start + batch, end)\n",
    "    pk = pd.read_pickle(str(batch_end) + \"_1.pkl\")\n",
    "    pk = pk.astype('float32')\n",
    "    \n",
    "    y = []\n",
    "    for i in range(batch_start, batch_end):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    #머신러닝 자체의 시간을 계산해봄\n",
    "    start_time = time.time() \n",
    "    svr_model.fit(pk, y['CAR'])\n",
    "    predictions = svr_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) #mse 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    svr_results = pd.DataFrame(predictions, columns=['SVR'])\n",
    "    svr_results = pd.concat([y, svr_results], axis=1)\n",
    "    svr_results.to_csv(str(batch_end) + '_SVR_CPU.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    # 총 걸린시간에 합산함\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, svr_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 SVR 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del svr_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05d4c1-0721-4027-b672-7573aaa4ae7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd97ec3-720f-4478-8b7e-fc05dcbaa4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Random Forest 학습 시간 (CPU): 5095.119078159332\n",
      "전체 RMSE: 0.045324268005599834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "# CPU 기반 Random Forest 모델 구축\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "batch = 455\n",
    "end = len(ss)\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    batch_end = min(batch_start + batch, end)\n",
    "    pk = pd.read_pickle(str(batch_end) + \"_1.pkl\")\n",
    "    pk = pk.astype('float32')\n",
    "    \n",
    "    y = []\n",
    "    for i in range(batch_start, batch_end):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    # 머신러닝 학습과 예측 시간 측정\n",
    "    start_time = time.time() \n",
    "    rf_model.fit(pk, y['CAR'])\n",
    "    predictions = rf_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) # MSE 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    rf_results = pd.DataFrame(predictions, columns=['RF'])\n",
    "    rf_results = pd.concat([y, rf_results], axis=1)\n",
    "    rf_results.to_csv(str(batch_end) + '_RF_CPU.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    # 총 걸린 시간에 합산\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, rf_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 Random Forest 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del rf_model\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e04984-3e1c-4486-ba3c-25775a99ef56",
   "metadata": {},
   "source": [
    "### 그래디언트부스트 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291e01f2-08a4-4a68-9d6e-d4ce41975780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Gradient Boosting 학습 시간 (CPU): 1349.7038168907166\n",
      "전체 RMSE: 0.0316019272017455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "# CPU 기반 Gradient Boosting 모델 구축\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "batch = 455\n",
    "end = len(ss)\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    batch_end = min(batch_start + batch, end)\n",
    "    pk = pd.read_pickle(str(batch_end) + \"_1.pkl\")\n",
    "    pk = pk.astype('float32')\n",
    "    \n",
    "    y = []\n",
    "    for i in range(batch_start, batch_end):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    # 머신러닝 학습과 예측 시간 측정\n",
    "    start_time = time.time() \n",
    "    gb_model.fit(pk, y['CAR'])\n",
    "    predictions = gb_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) # MSE 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    gb_results = pd.DataFrame(predictions, columns=['GB'])\n",
    "    gb_results = pd.concat([y, gb_results], axis=1)\n",
    "    gb_results.to_csv(str(batch_end) + '_GB_CPU.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    # 총 걸린 시간에 합산\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, gb_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 Gradient Boosting 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del gb_model\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cd19a1d-ff71-4430-aaff-feac118bb06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch = 455\n",
    "end = len(ss)\n",
    "d1 = pd.DataFrame()\n",
    "for batch_start in range(0, end, batch):\n",
    "    batch_end = min(batch_start + batch, end)\n",
    "    d2 = pd.read_csv(str(batch_end)+'_GB_CPU.csv',index_col = 0)\n",
    "    d2 = d2.rename(columns={'GB': 'GB_CPU'})\n",
    "    \n",
    "    d3 = pd.read_csv(str(batch_end)+'_RF_CPU.csv',index_col = 0)\n",
    "    d3 = d3.rename(columns={'RF': 'RF_CPU'})\n",
    "    d3 = d3.drop(columns = ['CAR'])\n",
    "    \n",
    "    d4 = pd.read_csv(str(batch_end)+'_SVR_CPU.csv',index_col = 0)\n",
    "    d4 = d4.rename(columns={'SVR': 'SVR_CPU'})\n",
    "    d4 = d4.drop(columns = ['CAR'])\n",
    "\n",
    "    d5 = pd.read_csv(str(batch_end)+'_SVR_GPU.csv',index_col = 0)\n",
    "    d5 = d5.rename(columns={'SVR': 'SVR_GPU'})\n",
    "    d5 = d5.drop(columns = ['CAR'])\n",
    "\n",
    "    dd = pd.concat([d2, d3, d4, d5], axis=1)\n",
    "    d1 = pd.concat([d1, dd], ignore_index=True)\n",
    "\n",
    "d1.to_csv('CAR_455.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba7ca3-a774-4f4b-b280-3c22f9f23aa6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<oi>\n",
    "    배치의 크기는 455개로 작고, 각 데이터 (배치 내에서의 각 row들) 이 47만에 달하는 컬럼수를 가지는 탓에 CPU로 작업을 한 경우 더 빠른 것으로 나타나고 있다. <br>\n",
    "    머신러닝 적합에 있어서 병렬 구조의 gpu는 cpu보다 적합에 있어 더 빠른 것으로 알려져 있으나, 이 데이터는 기형적으로 각 데이터의 컬럼수 가 너무 많은 탓에 <br>\n",
    "    최대 불러올 수 있는 크기가 500개 언저리인 탓에 gpu의 효유성을 느끼지 못하고 있는 것 같다. <br>\n",
    "    또한 GPU로 랜덤포레스트를 해보려고 하여도 트리의 깊이가 워낙 깊어 메모리 에러로 인해 작업을 수행할 수 없기에, 기형적인 이 데이터 셋에 대해서는 CPU 위주로 작업을 하고 <br>\n",
    "    배치 사이즈를 더 키워서 머신러닝 적합을 해 보고자 한다. <br>\n",
    "\n",
    "<center><b>머신러닝 결과 표 - 455개의 배치</b></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "|       | Time  | RMSE | \n",
    "|-------|-----------------|--------------------|\n",
    "| SVR(GPU)  | 2208   | 0.1146  | \n",
    "| SVR(CPU)  | 546 |  0.1146      |\n",
    "| RF(CPU)  | 5095   | 0.0453      | \n",
    "| GB(CPU) | 1349   | 0.0316     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7bed0-673a-47a7-83d3-4a45c6bc4eeb",
   "metadata": {},
   "source": [
    "### 455*31 개의 형태이므로 6개씩 묶어서 작업하고 마지막에 대해선 7개로 작업을 진행함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e157e-e040-49eb-9209-da42add8bc5c",
   "metadata": {},
   "source": [
    "### CPU기반 SVR, 455배치 3개씩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70496f-12bc-4947-8b54-e987e3f29f56",
   "metadata": {},
   "source": [
    "### 데이터 다시 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5d5338-2472-4d99-8758-ff4638159015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import cuml\n",
    "import cudf\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "ss = pd.read_csv('gram_sample_CIK_filed.csv', encoding='cp949')\n",
    "for i in range(0, len(ss)):\n",
    "    ss.loc[i,'key'] = ss.loc[i, 'name']+'-'+str(ss.loc[i, 'year'])\n",
    "\n",
    "with open('firm_year_gram_count_car_LMratio.pkl', 'rb') as f:\n",
    "    firm_year_gram_count = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7bdbbc5-da88-41b5-a52f-303978b9885c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 SVR 학습 시간 (CPU): 1305.7770247459412\n",
      "전체 RMSE: 0.11857238968542118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# CPU 기반 SVR 모델 구축\n",
    "svr_model = SVR(kernel='rbf')\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    y = []\n",
    "    \n",
    "    batch_end1 = min(batch_start + 455, end)\n",
    "    pk1 = pd.read_pickle(str(batch_end1) + \"_1.pkl\")\n",
    "    pk1 = pk1.astype('float32')\n",
    "        \n",
    "    batch_end2 = min(batch_end1 + 455, end)\n",
    "    pk2 = pd.read_pickle(str(batch_end2) + \"_1.pkl\")\n",
    "    pk2 = pk2.astype('float32')\n",
    "    \n",
    "    batch_end3 = min(batch_end2 + 455, end)\n",
    "    pk3 = pd.read_pickle(str(batch_end3) + \"_1.pkl\")\n",
    "    pk3 = pk3.astype('float32')\n",
    "   \n",
    "    for i in range(batch_start, batch_end3):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    \n",
    "    if batch_end3 == end:\n",
    "        pk4 = pd.read_pickle(str(batch_end3+455) + \"_1.pkl\")\n",
    "        pk4 = pk4.astype('float32')\n",
    "        pk3 = pd.concat([pk3, pk4], ignore_index=True)\n",
    "\n",
    "        for i in range(batch_end3, batch_end3+455):\n",
    "            firm = ss.loc[i, 'key']\n",
    "            y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "       \n",
    "    pk = pd.concat([pk1,pk2,pk3])  \n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    #머신러닝 자체의 시간을 계산해봄\n",
    "    start_time = time.time() \n",
    "    svr_model.fit(pk, y['CAR'])\n",
    "    predictions = svr_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) #mse 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    svr_results = pd.DataFrame(predictions, columns=['SVR'])\n",
    "    svr_results = pd.concat([y, svr_results], axis=1)\n",
    "    svr_results.to_csv(str(batch_end3) + '_SVR_CPU_4556.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    # 총 걸린시간에 합산함\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, svr_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 SVR 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del svr_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b5fce-f696-4545-9c77-bd64a40abfde",
   "metadata": {},
   "source": [
    "### CPU기반 RF, 455배치 3개씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d2bc3d5-8d5d-459d-89ce-b5a09dce1363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Random Forest 학습 시간 (CPU): 8101.543528556824\n",
      "전체 RMSE: 0.05139839379391767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# CPU 기반 Random Forest 모델 구축\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    y = []\n",
    "    \n",
    "    batch_end1 = min(batch_start + 455, end)\n",
    "    pk1 = pd.read_pickle(str(batch_end1) + \"_1.pkl\")\n",
    "    pk1 = pk1.astype('float32')\n",
    "        \n",
    "    batch_end2 = min(batch_end1 + 455, end)\n",
    "    pk2 = pd.read_pickle(str(batch_end2) + \"_1.pkl\")\n",
    "    pk2 = pk2.astype('float32')\n",
    "    \n",
    "    batch_end3 = min(batch_end2 + 455, end)\n",
    "    pk3 = pd.read_pickle(str(batch_end3) + \"_1.pkl\")\n",
    "    pk3 = pk3.astype('float32')\n",
    "   \n",
    "    for i in range(batch_start, batch_end3):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    \n",
    "    if batch_end3 == end:\n",
    "        pk4 = pd.read_pickle(str(batch_end3+455) + \"_1.pkl\")\n",
    "        pk4 = pk4.astype('float32')\n",
    "        pk3 = pd.concat([pk3, pk4], ignore_index=True)\n",
    "\n",
    "        for i in range(batch_end3, batch_end3+455):\n",
    "            firm = ss.loc[i, 'key']\n",
    "            y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "       \n",
    "    pk = pd.concat([pk1,pk2,pk3])  \n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    # 머신러닝 학습과 예측 시간 측정\n",
    "    start_time = time.time() \n",
    "    rf_model.fit(pk, y['CAR'])\n",
    "    predictions = rf_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) # MSE 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    rf_results = pd.DataFrame(predictions, columns=['RF'])\n",
    "    rf_results = pd.concat([y, rf_results], axis=1)\n",
    "    rf_results.to_csv(str(batch_end3) + '_RF_CPU_4556.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    # 총 걸린 시간에 합산\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, rf_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 Random Forest 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del rf_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9a878c-76b9-4464-86e2-751106aa6912",
   "metadata": {},
   "source": [
    "### CPU기반 GB, 455배치 3개씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298777e3-d7a1-4c10-9939-f2ee39777ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Gradient Boosting 학습 시간 (CPU): 1225.5256366729736\n",
      "전체 RMSE: 0.05017679497557742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# CPU 기반 Gradient Boosting 모델 구축\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    y = []\n",
    "    \n",
    "    batch_end1 = min(batch_start + 455, end)\n",
    "    pk1 = pd.read_pickle(str(batch_end1) + \"_1.pkl\")\n",
    "    pk1 = pk1.astype('float32')\n",
    "        \n",
    "    batch_end2 = min(batch_end1 + 455, end)\n",
    "    pk2 = pd.read_pickle(str(batch_end2) + \"_1.pkl\")\n",
    "    pk2 = pk2.astype('float32')\n",
    "    \n",
    "    batch_end3 = min(batch_end2 + 455, end)\n",
    "    pk3 = pd.read_pickle(str(batch_end3) + \"_1.pkl\")\n",
    "    pk3 = pk3.astype('float32')\n",
    "   \n",
    "    for i in range(batch_start, batch_end3):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    \n",
    "    if batch_end3 == end:\n",
    "        pk4 = pd.read_pickle(str(batch_end3+455) + \"_1.pkl\")\n",
    "        pk4 = pk4.astype('float32')\n",
    "        pk3 = pd.concat([pk3, pk4], ignore_index=True)\n",
    "\n",
    "        for i in range(batch_end3, batch_end3+455):\n",
    "            firm = ss.loc[i, 'key']\n",
    "            y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "       \n",
    "    pk = pd.concat([pk1,pk2,pk3])  \n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    # 머신러닝 학습과 예측 시간 측정\n",
    "    start_time = time.time() \n",
    "    gb_model.fit(pk, y['CAR'])\n",
    "    predictions = gb_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) # MSE 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    gb_results = pd.DataFrame(predictions, columns=['GB'])\n",
    "    gb_results = pd.concat([y, gb_results], axis=1)\n",
    "    gb_results.to_csv(str(batch_end3) + '_GB_CPU_4556.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    # 총 걸린 시간에 합산\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, gb_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 Gradient Boosting 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del gb_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "438d2b21-a53a-4f9d-bccf-7fe771d5817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "d = pd.read_csv('CAR_455.csv', encoding='cp949', index_col=0)\n",
    "d1 = pd.DataFrame()\n",
    "for batch_start in range(0, end, batch):\n",
    "    batch_end = min(batch_start + batch, end)\n",
    "    d2 = pd.read_csv(str(batch_end)+'_GB_CPU_4556.csv',index_col = 0)\n",
    "    d2 = d2.rename(columns={'GB': 'GB_CPU_4553'})\n",
    "    d2 = d2.drop(columns = ['CAR'])\n",
    "    \n",
    "    d3 = pd.read_csv(str(batch_end)+'_RF_CPU_4556.csv',index_col = 0)\n",
    "    d3 = d3.rename(columns={'RF': 'RF_CPU_4553'})\n",
    "    d3 = d3.drop(columns = ['CAR'])\n",
    "    \n",
    "    d4 = pd.read_csv(str(batch_end)+'_SVR_CPU_4556.csv',index_col = 0)\n",
    "    d4 = d4.rename(columns={'SVR': 'SVR_CPU_4553'})\n",
    "    d4 = d4.drop(columns = ['CAR'])\n",
    "\n",
    "    dd = pd.concat([d2, d3, d4], axis=1)\n",
    "    d1 = pd.concat([d1, dd], ignore_index=True)\n",
    "\n",
    "d = pd.concat([d, d1], axis=1)\n",
    "d.to_csv('CAR_4553.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb8b772-81d3-46fa-96c2-cee148452fe4",
   "metadata": {},
   "source": [
    "<center><b>머신러닝 결과 표 - 455*3 배치 추가</b></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "|       | Time  | RMSE | \n",
    "|-------|-----------------|--------------------|\n",
    "| SVR(GPU)  | 2208   | 0.1146  | \n",
    "| SVR(CPU)  | 546 |  0.1146      |\n",
    "| RF(CPU)  | 5095   | 0.0453      | \n",
    "| GB(CPU) | 1349   | 0.0316     |\n",
    "| SVR3(CPU)  | 1305 |  0.1185     |\n",
    "| RF3(CPU)  | 8101  | 0.0513     | \n",
    "| GB3(CPU) | 1225   | 0.0517    |\n",
    "</table>\n",
    "<br>\n",
    "그래디언트 부스트를 제외하고, 전부 작업 시간이 증가하였으며, 모든 모델 전부 RMSE가 증가한 것을 확인 가능하다. <br>\n",
    "이제 통제변수를 추가하여, LM 단어집과, 머신러닝을 이용하여 예측한 CAR 값들 간의 회귀를 통하여 어떠한 결과가 나타나는지 확인해 보도록 하겠다 <br>\n",
    "뿐만 아니라, 기존의 선행연구들과 유사하게, 기업 특성 통제변수를 몇 가지 추가한 상태로 회귀를 진행해보도록 하자 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6cc8e03-8e07-480e-aa14-8cb3e6ad3b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['unigrams', 'bigrams', 'CAR[0,1]', 'positive_ratio', 'negative_ratio', 'PN', 'PN2', 'sale', 'lnmkv', 'bperhare'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firm_year_gram_count['1 800 FLOWERS COM INC-2014'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c8b4bef-ba1a-4056-af23-6b81777ff8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "neg = []\n",
    "PN = []\n",
    "PN2 = []\n",
    "sale = []\n",
    "lnmkv = []\n",
    "bperhare = []\n",
    "for i in range(0, len(ss)):\n",
    "    firm = ss.loc[i, 'key'] #불러오는 이유는 혹시 dictionary에서 순서가 잘못되었을수도 있어서.. key 기준으로 기존 머신러닝 정렬했으니 통일하려고\n",
    "    pos.append(firm_year_gram_count[firm]['positive_ratio'])\n",
    "    neg.append(firm_year_gram_count[firm]['negative_ratio'])\n",
    "    PN.append(firm_year_gram_count[firm]['PN'])\n",
    "    PN2.append(firm_year_gram_count[firm]['PN2'])\n",
    "    sale.append(firm_year_gram_count[firm]['sale'])\n",
    "    lnmkv.append(firm_year_gram_count[firm]['lnmkv'])\n",
    "    bperhare.append(firm_year_gram_count[firm]['bperhare'])\n",
    "pos = pd.DataFrame(pos, columns=['positive_ratio'])\n",
    "neg = pd.DataFrame(neg, columns=['negative_ratio'])\n",
    "PN = pd.DataFrame(PN, columns=['PN'])\n",
    "PN2 = pd.DataFrame(PN2, columns=['PN2'])\n",
    "sale = pd.DataFrame(sale, columns=['sale'])\n",
    "lnmkv = pd.DataFrame(lnmkv, columns=['lnmkv'])\n",
    "bperhare = pd.DataFrame(bperhare, columns=['bperhare'])\n",
    "\n",
    "ddd = pd.concat([d,pos, neg, PN, PN2, sale, lnmkv, bperhare], axis=1)\n",
    "\n",
    "ddd.to_csv('CAR_control.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3d5b872-7110-43ba-8b48-5a243d80443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================================================================================================\n",
      "                 GB_CPU     RF_CPU    SVR_CPU   SVR_GPU  GB_CPU_4553 RF_CPU_4553 SVR_CPU_4553 positive_ratio negative_ratio     PN        PN2    \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept      -0.0016**  -0.0004    0.0095*** 0.0095*** -0.0030***  -0.0008     0.0117***    0.0111         0.0252***      0.0180***  0.0163*** \n",
      "               (0.0007)   (0.0007)   (0.0024)  (0.0024)  (0.0011)    (0.0008)    (0.0025)     (0.0077)       (0.0058)       (0.0043)   (0.0039)  \n",
      "sale           -0.0000    -0.0000*   -0.0000   -0.0000   -0.0000     -0.0000     -0.0000      0.0000         0.0000         0.0000     0.0000    \n",
      "               (0.0000)   (0.0000)   (0.0000)  (0.0000)  (0.0000)    (0.0000)    (0.0000)     (0.0000)       (0.0000)       (0.0000)   (0.0000)  \n",
      "lnmkv          0.0003**   0.0001     -0.0003   -0.0003   0.0005***   0.0001      -0.0007*     -0.0013***     -0.0011***     -0.0011*** -0.0011***\n",
      "               (0.0001)   (0.0001)   (0.0004)  (0.0004)  (0.0002)    (0.0001)    (0.0004)     (0.0004)       (0.0004)       (0.0004)   (0.0004)  \n",
      "bperhare       -0.0000*** -0.0000*** 0.0000    0.0000    -0.0000***  -0.0000***  0.0000       0.0000***      0.0000***      0.0000***  0.0000*** \n",
      "               (0.0000)   (0.0000)   (0.0000)  (0.0000)  (0.0000)    (0.0000)    (0.0000)     (0.0000)       (0.0000)       (0.0000)   (0.0000)  \n",
      "GB_CPU         1.0952***                                                                                                                         \n",
      "               (0.0025)                                                                                                                          \n",
      "RF_CPU                    1.3168***                                                                                                              \n",
      "                          (0.0030)                                                                                                               \n",
      "SVR_CPU                              1.0408***                                                                                                   \n",
      "                                     (0.0172)                                                                                                    \n",
      "SVR_GPU                                        1.0405***                                                                                         \n",
      "                                               (0.0172)                                                                                          \n",
      "GB_CPU_4553                                              1.1317***                                                                               \n",
      "                                                         (0.0045)                                                                                \n",
      "RF_CPU_4553                                                          1.3614***                                                                   \n",
      "                                                                     (0.0034)                                                                    \n",
      "SVR_CPU_4553                                                                     1.0512***                                                       \n",
      "                                                                                 (0.0192)                                                        \n",
      "positive_ratio                                                                                -0.1098                                            \n",
      "                                                                                              (0.2144)                                           \n",
      "negative_ratio                                                                                               -0.2132***                          \n",
      "                                                                                                             (0.0608)                            \n",
      "PN                                                                                                                          0.0264***            \n",
      "                                                                                                                            (0.0083)             \n",
      "PN2                                                                                                                                    0.1783*** \n",
      "                                                                                                                                       (0.0568)  \n",
      "R-squared      0.9340     0.9348     0.2252    0.2252    0.8292      0.9237      0.1934       0.0127         0.0136         0.0134     0.0134    \n",
      "R-squared Adj. 0.9340     0.9348     0.2250    0.2250    0.8291      0.9237      0.1932       0.0124         0.0133         0.0131     0.0131    \n",
      "=================================================================================================================================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "X = ['GB_CPU', 'RF_CPU', 'SVR_CPU', 'SVR_GPU', 'GB_CPU_4553','RF_CPU_4553',\n",
    "     'SVR_CPU_4553', 'positive_ratio', 'negative_ratio', 'PN', 'PN2']\n",
    "\n",
    "models = []\n",
    "\n",
    "for x in X:\n",
    "    formula = f'CAR ~ sale + lnmkv + bperhare + {x}'\n",
    "    model = smf.ols(formula, data=ddd).fit()\n",
    "    models.append(model)\n",
    "          \n",
    "dfoutput = summary_col(models, stars=True, model_names=X)\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70784008-2465-41e8-a601-56b2fa3dd2a2",
   "metadata": {},
   "source": [
    "### result & conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2109ac0-f0d8-41f3-9ff7-d80f84e997f4",
   "metadata": {},
   "source": [
    "<io>\n",
    "분석 결과, 455개의 배치 기준으로 각각에 머신러닝 적합을 한 경우, 3 배치씩 묶어서 머신러닝 적합을 한 결과에 비해 더 높은 R-square를 보였다. <br>\n",
    "하지만 Randomforrest 의 경우, R_sqaure의 하락이 그렇게 크지 않았으며, 3 모형 중 랜덤포레스트가 가장 높은 R-square를 보였다. <br>\n",
    "또한, 기존의 LM 단어집에 비해 머신러닝 적합을 한 경우 더 높은 R-squre를 보였으며, 긍정 단어의 수는 유의성이 나타나지 않았으며 <br>\n",
    "부정 단어의 음의 유의성과, 긍정/부정 단어 비율의 경우 유의한 양의 결과가 나오는 것은 10-K filling date의 직후 CAR을 다룬 기존 선행연구들과 유사한 결과이다. <br>\n",
    "허나, LM단어의 10-K 예측이 최근에 연구에선 잘 맞지 않다는 연구결과가 존재하기에, 지금의 방식과 같이 머신러닝 기반 예측이 도움이 될 것으로 기대된다. <br>\n",
    "또한, 그 중에서 random forrest의 경우 예측에 잘 맞는 tree 만 쓴다는 점에서 프루닝의 개념이 첨가되어 있어, 더욱 더 높은 정확도를 보이는 것으로 예상된다. <br>\n",
    "\n",
    "추후 연구에선, 현재 각 data 행의 경우 47만개의 row이기 때문에 gpu의 장점을 살리지 못하기에, 자연어 토큰 기반, 딥러닝을 첨가한 요약집을 바탕으로 열 수를 줄여 <br>\n",
    "GPU와 CPU의 성능, 효율 등을 비교 가능할 것이며, 사업설명이 적혀있는 business description 부분만이 아닌 전체 데이터에 대한 분석 역시 진행 가능할 것 이다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48751487-603c-47c0-9f42-d54ae60d0d2d",
   "metadata": {},
   "source": [
    "### 추가 분석 : RF가 성능이 제일 좋다면 decision tree를 이용한다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e6b596f-b915-425f-9467-e6341309adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Decision Tree 학습 시간 (CPU): 191.86391687393188\n",
      "전체 RMSE: 0.0010875659563371579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "dt_model = DecisionTreeRegressor() #ccp_alpha=0.01 -> 프루닝시, 만일 DT 성능 종으면 프루닝 숫자 바꿔가면서 마지막으로 해보자\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    y = []\n",
    "    \n",
    "    batch_end1 = min(batch_start + 455, end)\n",
    "    pk1 = pd.read_pickle(str(batch_end1) + \"_1.pkl\")\n",
    "    pk1 = pk1.astype('float32')\n",
    "        \n",
    "    batch_end2 = min(batch_end1 + 455, end)\n",
    "    pk2 = pd.read_pickle(str(batch_end2) + \"_1.pkl\")\n",
    "    pk2 = pk2.astype('float32')\n",
    "    \n",
    "    batch_end3 = min(batch_end2 + 455, end)\n",
    "    pk3 = pd.read_pickle(str(batch_end3) + \"_1.pkl\")\n",
    "    pk3 = pk3.astype('float32')\n",
    "   \n",
    "    for i in range(batch_start, batch_end3):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    \n",
    "    if batch_end3 == end:\n",
    "        pk4 = pd.read_pickle(str(batch_end3+455) + \"_1.pkl\")\n",
    "        pk4 = pk4.astype('float32')\n",
    "        pk3 = pd.concat([pk3, pk4], ignore_index=True)\n",
    "\n",
    "        for i in range(batch_end3, batch_end3+455):\n",
    "            firm = ss.loc[i, 'key']\n",
    "            y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "       \n",
    "    pk = pd.concat([pk1,pk2,pk3])  \n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    # 머신러닝 학습과 예측 시간 측정\n",
    "    start_time = time.time()\n",
    "    dt_model.fit(pk, y['CAR'])\n",
    "    predictions = dt_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) # MSE 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    dt_results = pd.DataFrame(predictions, columns=['DT'])\n",
    "    dt_results = pd.concat([y, dt_results], axis=1)\n",
    "    dt_results.to_csv(str(batch_end3) + '_DT_CPU_4556.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, dt_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 Decision Tree 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del dt_model\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7a0d888-fb11-473e-a110-c564fa89e288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Decision Tree_0.001 학습 시간 (CPU): 183.05551266670227\n",
      "전체 RMSE: 0.07969894223663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "dt_model = DecisionTreeRegressor(ccp_alpha=0.001) #ccp_alpha=0.01 -> 프루닝시, 만일 DT 성능 종으면 프루닝 숫자 바꿔가면서 마지막으로 해보자\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    y = []\n",
    "    \n",
    "    batch_end1 = min(batch_start + 455, end)\n",
    "    pk1 = pd.read_pickle(str(batch_end1) + \"_1.pkl\")\n",
    "    pk1 = pk1.astype('float32')\n",
    "        \n",
    "    batch_end2 = min(batch_end1 + 455, end)\n",
    "    pk2 = pd.read_pickle(str(batch_end2) + \"_1.pkl\")\n",
    "    pk2 = pk2.astype('float32')\n",
    "    \n",
    "    batch_end3 = min(batch_end2 + 455, end)\n",
    "    pk3 = pd.read_pickle(str(batch_end3) + \"_1.pkl\")\n",
    "    pk3 = pk3.astype('float32')\n",
    "   \n",
    "    for i in range(batch_start, batch_end3):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    \n",
    "    if batch_end3 == end:\n",
    "        pk4 = pd.read_pickle(str(batch_end3+455) + \"_1.pkl\")\n",
    "        pk4 = pk4.astype('float32')\n",
    "        pk3 = pd.concat([pk3, pk4], ignore_index=True)\n",
    "\n",
    "        for i in range(batch_end3, batch_end3+455):\n",
    "            firm = ss.loc[i, 'key']\n",
    "            y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "       \n",
    "    pk = pd.concat([pk1,pk2,pk3])  \n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    # 머신러닝 학습과 예측 시간 측정\n",
    "    start_time = time.time()\n",
    "    dt_model.fit(pk, y['CAR'])\n",
    "    predictions = dt_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) # MSE 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    dt_results = pd.DataFrame(predictions, columns=['DT'])\n",
    "    dt_results = pd.concat([y, dt_results], axis=1)\n",
    "    dt_results.to_csv(str(batch_end3) + '_DT_CPU_4556_0.001.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, dt_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 Decision Tree_0.001 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del dt_model\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5251b6ce-9d77-437c-a61a-48c3d9d63534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Decision Tree_0.01 학습 시간 (CPU): 183.5637948513031\n",
      "전체 RMSE: 0.10640376265047138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "dt_model = DecisionTreeRegressor(ccp_alpha=0.01) #ccp_alpha=0.01 -> 프루닝시, 만일 DT 성능 종으면 프루닝 숫자 바꿔가면서 마지막으로 해보자\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    y = []\n",
    "    \n",
    "    batch_end1 = min(batch_start + 455, end)\n",
    "    pk1 = pd.read_pickle(str(batch_end1) + \"_1.pkl\")\n",
    "    pk1 = pk1.astype('float32')\n",
    "        \n",
    "    batch_end2 = min(batch_end1 + 455, end)\n",
    "    pk2 = pd.read_pickle(str(batch_end2) + \"_1.pkl\")\n",
    "    pk2 = pk2.astype('float32')\n",
    "    \n",
    "    batch_end3 = min(batch_end2 + 455, end)\n",
    "    pk3 = pd.read_pickle(str(batch_end3) + \"_1.pkl\")\n",
    "    pk3 = pk3.astype('float32')\n",
    "   \n",
    "    for i in range(batch_start, batch_end3):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    \n",
    "    if batch_end3 == end:\n",
    "        pk4 = pd.read_pickle(str(batch_end3+455) + \"_1.pkl\")\n",
    "        pk4 = pk4.astype('float32')\n",
    "        pk3 = pd.concat([pk3, pk4], ignore_index=True)\n",
    "\n",
    "        for i in range(batch_end3, batch_end3+455):\n",
    "            firm = ss.loc[i, 'key']\n",
    "            y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "       \n",
    "    pk = pd.concat([pk1,pk2,pk3])  \n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    # 머신러닝 학습과 예측 시간 측정\n",
    "    start_time = time.time()\n",
    "    dt_model.fit(pk, y['CAR'])\n",
    "    predictions = dt_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) # MSE 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    dt_results = pd.DataFrame(predictions, columns=['DT'])\n",
    "    dt_results = pd.concat([y, dt_results], axis=1)\n",
    "    dt_results.to_csv(str(batch_end3) + '_DT_CPU_4556_0.01.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, dt_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 Decision Tree_0.01 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del dt_model\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "149d43f8-ce36-4316-bb05-5e5ffb22d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Decision Tree_0.1 학습 시간 (CPU): 181.48838877677917\n",
      "전체 RMSE: 0.13663168005148477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "dt_model = DecisionTreeRegressor(ccp_alpha=0.1) #ccp_alpha=0.01 -> 프루닝시, 만일 DT 성능 종으면 프루닝 숫자 바꿔가면서 마지막으로 해보자\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "total_time = 0\n",
    "mse_values = []\n",
    "\n",
    "for batch_start in range(0, end, batch):\n",
    "    y = []\n",
    "    \n",
    "    batch_end1 = min(batch_start + 455, end)\n",
    "    pk1 = pd.read_pickle(str(batch_end1) + \"_1.pkl\")\n",
    "    pk1 = pk1.astype('float32')\n",
    "        \n",
    "    batch_end2 = min(batch_end1 + 455, end)\n",
    "    pk2 = pd.read_pickle(str(batch_end2) + \"_1.pkl\")\n",
    "    pk2 = pk2.astype('float32')\n",
    "    \n",
    "    batch_end3 = min(batch_end2 + 455, end)\n",
    "    pk3 = pd.read_pickle(str(batch_end3) + \"_1.pkl\")\n",
    "    pk3 = pk3.astype('float32')\n",
    "   \n",
    "    for i in range(batch_start, batch_end3):\n",
    "        firm = ss.loc[i, 'key']\n",
    "        y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "    \n",
    "    if batch_end3 == end:\n",
    "        pk4 = pd.read_pickle(str(batch_end3+455) + \"_1.pkl\")\n",
    "        pk4 = pk4.astype('float32')\n",
    "        pk3 = pd.concat([pk3, pk4], ignore_index=True)\n",
    "\n",
    "        for i in range(batch_end3, batch_end3+455):\n",
    "            firm = ss.loc[i, 'key']\n",
    "            y.append(firm_year_gram_count[firm]['CAR[0,1]'])\n",
    "       \n",
    "    pk = pd.concat([pk1,pk2,pk3])  \n",
    "    y = pd.DataFrame(y, columns=['CAR'])\n",
    "\n",
    "    # 머신러닝 학습과 예측 시간 측정\n",
    "    start_time = time.time()\n",
    "    dt_model.fit(pk, y['CAR'])\n",
    "    predictions = dt_model.predict(pk)\n",
    "    mse = mean_squared_error(y['CAR'], predictions) # MSE 계산\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    # 결과 저장\n",
    "    dt_results = pd.DataFrame(predictions, columns=['DT'])\n",
    "    dt_results = pd.concat([y, dt_results], axis=1)\n",
    "    dt_results.to_csv(str(batch_end3) + '_DT_CPU_4556_0.1.csv', encoding='cp949')\n",
    "    end_time = time.time()\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del pk, y, dt_results, predictions\n",
    "    gc.collect()\n",
    "\n",
    "print('총 Decision Tree_0.1 학습 시간 (CPU):', total_time)\n",
    "overall_mse = np.mean(mse_values)\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "print('전체 RMSE:', overall_rmse)\n",
    "\n",
    "del dt_model\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c717819-22ed-4ce9-a04d-11cdd05c38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch = 455*3\n",
    "end = len(ss) - 455\n",
    "d = pd.read_csv('CAR_control.csv', encoding='cp949', index_col=0)\n",
    "d1 = pd.DataFrame()\n",
    "for batch_start in range(0, end, batch):\n",
    "    batch_end = min(batch_start + batch, end)\n",
    "    d2 = pd.read_csv(str(batch_end)+'_DT_CPU_4556.csv',index_col = 0)\n",
    "    d2 = d2.rename(columns={'DT': 'DT_CPU_4553'})\n",
    "    d2 = d2.drop(columns = ['CAR'])\n",
    "    \n",
    "    d3 = pd.read_csv(str(batch_end)+'_DT_CPU_4556_0.001.csv',index_col = 0)\n",
    "    d3 = d3.rename(columns={'DT': 'DT_CPU_4553_0.001'})\n",
    "    d3 = d3.drop(columns = ['CAR'])\n",
    "    \n",
    "    d4 = pd.read_csv(str(batch_end)+'_DT_CPU_4556_0.01.csv',index_col = 0)\n",
    "    d4 = d4.rename(columns={'DT': 'DT_CPU_4553_0.01'})\n",
    "    d4 = d4.drop(columns = ['CAR'])\n",
    "\n",
    "    d5 = pd.read_csv(str(batch_end)+'_DT_CPU_4556_0.1.csv',index_col = 0)\n",
    "    d5 = d5.rename(columns={'DT': 'DT_CPU_4553_0.1'})\n",
    "    d5 = d5.drop(columns = ['CAR'])\n",
    "\n",
    "    dd = pd.concat([d2, d3, d4, d5], axis=1)\n",
    "    d1 = pd.concat([d1, dd], ignore_index=True)\n",
    "\n",
    "d = pd.concat([d, d1], axis=1)\n",
    "d.to_csv('CAR_control2.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70066ce-65dc-4910-ae10-33ef6a039a2d",
   "metadata": {},
   "source": [
    "<center><b>머신러닝 결과 표 - 455*3 배치 추가</b></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "|       | Time  | RMSE | \n",
    "|-------|-----------------|--------------------|\n",
    "| RF(CPU)  | 5095   | 0.0453      | \n",
    "| RF3(CPU)  | 8101  | 0.0513     | \n",
    "| DT(CPU)  | 191  | 0.0011     | \n",
    "| DT0.001(CPU)  | 183  | 0.0796    | \n",
    "| DT0.01(CPU)  | 183 | 0.1064    | \n",
    "| DT0.1(CPU)  | 181  | 0.1366     | \n",
    "</table>\n",
    "<br>\n",
    "프루닝 조건이 Decision Tree에서 엄격해질수록 시간 단축과 RMSE가 높아지는것을 볼 수 있다. <br>\n",
    "이제 이 값들을 기존 분석과 동일하게 CAR과의 회귀에 사용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3be71d3a-fe4a-4c5b-9dd8-3fb3b4d739e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================================================\n",
      "                         RF_CPU   RF_CPU_4553 DT_CPU_4553 DT_CPU_4553_0.001 DT_CPU_4553_0.01 DT_CPU_4553_0.1\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Intercept              -0.0004    -0.0008     -0.0000     -0.0020           0.0067***        0.0080***      \n",
      "                       (0.0007)   (0.0008)    (0.0000)    (0.0018)          (0.0022)         (0.0027)       \n",
      "sale                   -0.0000*   -0.0000     -0.0000     0.0000            0.0000           0.0000         \n",
      "                       (0.0000)   (0.0000)    (0.0000)    (0.0000)          (0.0000)         (0.0000)       \n",
      "lnmkv                  0.0001     0.0001      0.0000      0.0002            -0.0011***       -0.0012***     \n",
      "                       (0.0001)   (0.0001)    (0.0000)    (0.0003)          (0.0003)         (0.0004)       \n",
      "bperhare               -0.0000*** -0.0000***  0.0000      0.0000            0.0000***        0.0000***      \n",
      "                       (0.0000)   (0.0000)    (0.0000)    (0.0000)          (0.0000)         (0.0000)       \n",
      "RF_CPU                 1.3168***                                                                            \n",
      "                       (0.0030)                                                                             \n",
      "RF_CPU_4553                       1.3614***                                                                 \n",
      "                                  (0.0034)                                                                  \n",
      "DT_CPU_4553                                   1.0000***                                                     \n",
      "                                              (0.0001)                                                      \n",
      "Q('DT_CPU_4553_0.001')                                    1.0004***                                         \n",
      "                                                          (0.0075)                                          \n",
      "Q('DT_CPU_4553_0.01')                                                       0.9991***                       \n",
      "                                                                            (0.0111)                        \n",
      "Q('DT_CPU_4553_0.1')                                                                         0.5435**       \n",
      "                                                                                             (0.2120)       \n",
      "R-squared              0.9348     0.9237      0.9999      0.5739            0.3846           0.0131         \n",
      "R-squared Adj.         0.9348     0.9237      0.9999      0.5738            0.3844           0.0128         \n",
      "============================================================================================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "import pandas as pd\n",
    "\n",
    "ddd = pd.read_csv('CAR_control2.csv', encoding='cp949', index_col=0)\n",
    "\n",
    "X = ['RF_CPU', 'RF_CPU_4553', 'DT_CPU_4553', 'DT_CPU_4553_0.001', 'DT_CPU_4553_0.01', 'DT_CPU_4553_0.1']\n",
    "\n",
    "models = []\n",
    "\n",
    "for x in X:\n",
    "    if '.' in x: #0.001과 같은 경우 변수명이 안읽혀서 변수명을 새로 하기보단 방법을 찾아보니 {} 형태로 감싸기로 ㅎㅁ\n",
    "        formula = \"CAR ~ sale + lnmkv + bperhare + Q('{}')\".format(x)\n",
    "    else:\n",
    "        formula = 'CAR ~ sale + lnmkv + bperhare + {}'.format(x)\n",
    "    model = smf.ols(formula, data=ddd).fit()\n",
    "    models.append(model)\n",
    "          \n",
    "dfoutput = summary_col(models, stars=True, model_names=X)\n",
    "print(dfoutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fa4eb80-7bd8-46e5-9306-9483d2d90d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR</th>\n",
       "      <th>GB_CPU</th>\n",
       "      <th>RF_CPU</th>\n",
       "      <th>SVR_CPU</th>\n",
       "      <th>SVR_GPU</th>\n",
       "      <th>GB_CPU_4553</th>\n",
       "      <th>RF_CPU_4553</th>\n",
       "      <th>SVR_CPU_4553</th>\n",
       "      <th>positive_ratio</th>\n",
       "      <th>negative_ratio</th>\n",
       "      <th>PN</th>\n",
       "      <th>PN2</th>\n",
       "      <th>sale</th>\n",
       "      <th>lnmkv</th>\n",
       "      <th>bperhare</th>\n",
       "      <th>DT_CPU_4553</th>\n",
       "      <th>DT_CPU_4553_0.001</th>\n",
       "      <th>DT_CPU_4553_0.01</th>\n",
       "      <th>DT_CPU_4553_0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062292</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>0.029830</td>\n",
       "      <td>0.030036</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.027738</td>\n",
       "      <td>0.043576</td>\n",
       "      <td>0.094666</td>\n",
       "      <td>-0.369565</td>\n",
       "      <td>-0.051089</td>\n",
       "      <td>756.345</td>\n",
       "      <td>5.920677</td>\n",
       "      <td>2.8589</td>\n",
       "      <td>0.062292</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.008655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003595</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.031161</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>-0.006985</td>\n",
       "      <td>0.026860</td>\n",
       "      <td>0.040948</td>\n",
       "      <td>0.089799</td>\n",
       "      <td>-0.373626</td>\n",
       "      <td>-0.048851</td>\n",
       "      <td>1121.506</td>\n",
       "      <td>6.523892</td>\n",
       "      <td>3.2054</td>\n",
       "      <td>-0.003595</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.008655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.003817</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>0.028570</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>0.043892</td>\n",
       "      <td>0.096562</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.052670</td>\n",
       "      <td>1173.024</td>\n",
       "      <td>6.379215</td>\n",
       "      <td>3.7184</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.008655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.004102</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>0.027096</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>-0.006216</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.045421</td>\n",
       "      <td>0.098168</td>\n",
       "      <td>-0.367347</td>\n",
       "      <td>-0.052747</td>\n",
       "      <td>1193.625</td>\n",
       "      <td>6.455379</td>\n",
       "      <td>4.3328</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.008655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073336</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>-0.039274</td>\n",
       "      <td>0.026566</td>\n",
       "      <td>0.026767</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>-0.038009</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>0.043605</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.052326</td>\n",
       "      <td>1151.921</td>\n",
       "      <td>6.699709</td>\n",
       "      <td>4.8720</td>\n",
       "      <td>-0.073336</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.002546</td>\n",
       "      <td>-0.008655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CAR    GB_CPU    RF_CPU   SVR_CPU   SVR_GPU  GB_CPU_4553  RF_CPU_4553  \\\n",
       "0  0.062292  0.010994  0.036908  0.029830  0.030036    -0.000428     0.031726   \n",
       "1 -0.003595 -0.001089  0.004707  0.030952  0.031161    -0.000428    -0.006985   \n",
       "2 -0.003817  0.004312 -0.002415  0.028356  0.028570    -0.000428    -0.002817   \n",
       "3 -0.000403  0.000020 -0.004102  0.026880  0.027096    -0.000428    -0.006216   \n",
       "4 -0.073336 -0.023900 -0.039274  0.026566  0.026767    -0.000428    -0.038009   \n",
       "\n",
       "   SVR_CPU_4553  positive_ratio  negative_ratio        PN       PN2      sale  \\\n",
       "0      0.027738        0.043576        0.094666 -0.369565 -0.051089   756.345   \n",
       "1      0.026860        0.040948        0.089799 -0.373626 -0.048851  1121.506   \n",
       "2      0.023964        0.043892        0.096562 -0.375000 -0.052670  1173.024   \n",
       "3      0.023439        0.045421        0.098168 -0.367347 -0.052747  1193.625   \n",
       "4      0.026761        0.043605        0.095930 -0.375000 -0.052326  1151.921   \n",
       "\n",
       "      lnmkv  bperhare  DT_CPU_4553  DT_CPU_4553_0.001  DT_CPU_4553_0.01  \\\n",
       "0  5.920677    2.8589     0.062292          -0.002546         -0.002546   \n",
       "1  6.523892    3.2054    -0.003595          -0.002546         -0.002546   \n",
       "2  6.379215    3.7184    -0.003817          -0.002546         -0.002546   \n",
       "3  6.455379    4.3328    -0.000403          -0.002546         -0.002546   \n",
       "4  6.699709    4.8720    -0.073336          -0.002546         -0.002546   \n",
       "\n",
       "   DT_CPU_4553_0.1  \n",
       "0        -0.008655  \n",
       "1        -0.008655  \n",
       "2        -0.008655  \n",
       "3        -0.008655  \n",
       "4        -0.008655  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d2e1ea-5298-4960-bf71-dbb3b6bc4439",
   "metadata": {},
   "source": [
    "<oi>\n",
    "DT의 유의성이 높게 나오긴 하였지만 .head()를 통해 구조를 보면 CAR 자체를 그대로 인식하는것 같다. 즉 데이터의 열값이 반영이 안되는듯하다. <br>\n",
    "또한, 프루닝의 조건이 들어갈수록,  R-square가 떨어지면서 또한 모든 데이터가 같은 예측값을 가지게 된 듯 하다. <br>\n",
    "즉 프루닝은 계산 복잡도를 통하여 필요한 트리만 찾아 적합 시간이 줄어든다는 장점은 있으나, 이를 바탕으로 CAR과 회귀를 할 시 정확도에 의문이 존재한다. <br>\n",
    "그렇기에, 기존의 결론과 유사하게 Random Forrest의 경우 CAR과의 상관관계 분석에 유리하다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da067126-718c-4321-bc0c-6e52fefd8e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
